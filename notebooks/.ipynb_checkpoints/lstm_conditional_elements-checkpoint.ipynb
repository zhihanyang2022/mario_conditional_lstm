{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay  # from https://arxiv.org/pdf/1506.02078.pdf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunable_hparams = {\n",
    "    'stateful_generation' : True,\n",
    "    'mapping_type' : 'seq2seq',\n",
    "    'early_stopping' : False,\n",
    "    'seq_length' : 200,\n",
    "    'game' : 'mario'\n",
    "}\n",
    "fixed_hparams = {\n",
    "    'hidden_size' : 128,\n",
    "    'learning_rate' : 2e-3,\n",
    "    'learning_rate_decay' : 0.95,\n",
    "    'dropout' : 0.5,\n",
    "    'batch_size' : 100,\n",
    "    'num_layers' : 3,\n",
    "    'max_epochs' : 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in tunable_hparams.items():\n",
    "    exec(key + '=val')\n",
    "for key, val in fixed_hparams.items():\n",
    "    exec(key + '=val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "data = open('corpuses/mario_corpus_conditional.txt', 'r').read()\n",
    "level_strs = data.rstrip().split(')')[:-1]\n",
    "print(len(level_strs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', '-', '<', '>', '?', 'B', 'E', 'N', 'Q', 'S', 'X', 'Y', '[', ']', 'b', 'o', 'x'] 17\n"
     ]
    }
   ],
   "source": [
    "chars = []\n",
    "for level_str in level_strs:\n",
    "    chars.extend(list(level_str))\n",
    "chars = sorted(list(set(chars)))  # sorting is very important; otherwise the order is different each time\n",
    "vocab_size = len(chars)\n",
    "print(chars, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ix = { ch:i for i, ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i, ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_arrays = []\n",
    "for level_str in level_strs:\n",
    "    level_arrays.append(np.array([char_to_ix[char] for char in list(level_str)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs_and_targets_from_level_array(level_array):\n",
    "    \n",
    "    inputs, targets = [], []\n",
    "    \n",
    "    for i in range(len(level_array) - seq_length):\n",
    "        inputs.append(level_array[i:i+seq_length])\n",
    "        targets.append(level_array[i+1:i+seq_length+1])\n",
    "    \n",
    "    inputs, targets = map(np.array, [inputs, targets])\n",
    "    inputs = np.eye(vocab_size)[inputs]\n",
    "    \n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=37.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs, targets = [], []\n",
    "for level_array in tqdm(level_arrays, leave=False):\n",
    "    inputs_temp, targets_temp = get_inputs_and_targets_from_level_array(level_array)\n",
    "    inputs.extend(inputs_temp); targets.extend(targets_temp)\n",
    "inputs, targets = map(np.array, [inputs, targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156360, 200, 17), (156360, 200))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = ExponentialDecay(\n",
    "    initial_learning_rate=learning_rate,\n",
    "    decay_steps=len(inputs) // batch_size, \n",
    "    decay_rate=learning_rate_decay, \n",
    ")\n",
    "optimizer = RMSprop(learning_rate=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = EarlyStopping(\n",
    "    monitor='val_out_acc_custom_acc', mode='max', patience=2, restore_best_weights=early_stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "    return scce(\n",
    "        tf.reshape(y_true, shape=(tf.shape(y_true)[0] * seq_length, )), \n",
    "        tf.reshape(y_pred, shape=(tf.shape(y_pred)[0] * seq_length, vocab_size))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_acc(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(\n",
    "        tf.cast(\n",
    "            tf.math.equal(\n",
    "                tf.math.argmax(tf.reshape(y_pred, shape=(tf.shape(y_pred)[0] * seq_length, vocab_size)), axis=-1), \n",
    "                tf.cast(tf.reshape(y_true, shape=(tf.shape(y_true)[0] * seq_length, )), dtype=tf.int64)\n",
    "            ), \n",
    "            dtype=tf.float32\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_1_state_h_in = keras.layers.Input(shape=[hidden_size])\n",
    "lstm_1_state_c_in = keras.layers.Input(shape=[hidden_size])\n",
    "\n",
    "lstm_2_state_h_in = keras.layers.Input(shape=[hidden_size])\n",
    "lstm_2_state_c_in = keras.layers.Input(shape=[hidden_size])\n",
    "\n",
    "lstm_3_state_h_in = keras.layers.Input(shape=[hidden_size])\n",
    "lstm_3_state_c_in = keras.layers.Input(shape=[hidden_size])\n",
    "\n",
    "input = keras.layers.Input(shape=[seq_length, vocab_size])\n",
    "\n",
    "out, lstm_1_state_h_out, lstm_1_state_c_out = keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True)(\n",
    "    input, initial_state=[lstm_1_state_h_in, lstm_1_state_c_in]\n",
    ")\n",
    "out = layers.Dropout(dropout)(out)\n",
    "\n",
    "out, lstm_2_state_h_out, lstm_2_state_c_out = keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True)(\n",
    "    out, initial_state=[lstm_2_state_h_in, lstm_2_state_c_in]\n",
    ")\n",
    "out = layers.Dropout(dropout)(out)\n",
    "\n",
    "out, lstm_3_state_h_out, lstm_3_state_c_out = keras.layers.LSTM(hidden_size, return_sequences=True, return_state=True)(\n",
    "    out, initial_state=[lstm_3_state_h_in, lstm_3_state_c_in]\n",
    ")\n",
    "out = layers.Dropout(dropout)(out)\n",
    "\n",
    "out = layers.Dense(vocab_size)(out)\n",
    "out = layers.Activation('softmax')(out)\n",
    "\n",
    "out_acc = layers.Lambda(lambda x:x, name = \"out_acc\")(out)\n",
    "\n",
    "model = keras.models.Model(\n",
    "    inputs=[\n",
    "        input, \n",
    "        lstm_1_state_h_in, lstm_1_state_c_in,\n",
    "        lstm_2_state_h_in, lstm_2_state_c_in,\n",
    "        lstm_3_state_h_in, lstm_3_state_c_in\n",
    "    ], \n",
    "    outputs=[\n",
    "        out_acc,\n",
    "        lstm_1_state_h_out, lstm_1_state_c_out,\n",
    "        lstm_2_state_h_out, lstm_2_state_c_out,\n",
    "        lstm_3_state_h_out, lstm_3_state_c_out\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=[custom_loss, None, None, None, None, None, None], \n",
    "    loss_weights=[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    metrics={'out_acc':custom_acc},\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = np.zeros((len(inputs), hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1408/1408 [==============================] - 194s 138ms/step - loss: 0.3792 - out_acc_loss: 0.3792 - out_acc_custom_acc: 0.8819 - val_loss: 0.2726 - val_out_acc_loss: 0.2726 - val_out_acc_custom_acc: 0.9143\n",
      "Epoch 2/50\n",
      "1408/1408 [==============================] - 193s 137ms/step - loss: 0.1754 - out_acc_loss: 0.1754 - out_acc_custom_acc: 0.9447 - val_loss: 0.2596 - val_out_acc_loss: 0.2596 - val_out_acc_custom_acc: 0.9220\n",
      "Epoch 3/50\n",
      "1408/1408 [==============================] - 193s 137ms/step - loss: 0.1408 - out_acc_loss: 0.1408 - out_acc_custom_acc: 0.9548 - val_loss: 0.2659 - val_out_acc_loss: 0.2659 - val_out_acc_custom_acc: 0.9249\n",
      "Epoch 4/50\n",
      "1408/1408 [==============================] - 193s 137ms/step - loss: 0.1232 - out_acc_loss: 0.1232 - out_acc_custom_acc: 0.9601 - val_loss: 0.3073 - val_out_acc_loss: 0.3073 - val_out_acc_custom_acc: 0.9233\n",
      "Epoch 5/50\n",
      "1408/1408 [==============================] - 193s 137ms/step - loss: 0.1119 - out_acc_loss: 0.1119 - out_acc_custom_acc: 0.9636 - val_loss: 0.3332 - val_out_acc_loss: 0.3332 - val_out_acc_custom_acc: 0.9211\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [inputs, dummy, dummy, dummy, dummy, dummy, dummy], \n",
    "    [targets, dummy, dummy, dummy, dummy, dummy, dummy], \n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.1,\n",
    "    shuffle=True,\n",
    "    epochs=max_epochs, \n",
    "    callbacks=[es_callback]\n",
    ")\n",
    "for i in range(10):\n",
    "    model.save('trained_models/lstm_conditional_elements.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    'trained_models/lstm_conditional_elements.h5', \n",
    "    custom_objects={'custom_loss':custom_loss, 'custom_acc':custom_acc}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(\n",
    "    [inputs, dummy, dummy, dummy, dummy, dummy, dummy], \n",
    "    [targets, dummy, dummy, dummy, dummy, dummy, dummy],\n",
    "    batch_size=5, verbose=1\n",
    ")  # sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_to_string(onehot):\n",
    "    ints = np.argmax(onehot, axis=-1)\n",
    "    chars = [ix_to_char[ix] for ix in ints]\n",
    "    string = \"\".join(chars)\n",
    "    char_array = []\n",
    "    if len(string.rstrip().split('\\n')[-1]) < 22 - 1:  # minus 1 for new line char\n",
    "        for line in string.strip().split('\\n')[:-1]:\n",
    "            char_array.append(list(line[:21]))\n",
    "    else:\n",
    "        for line in string.strip().split('\\n')[:-1]:\n",
    "            char_array.append(list(line[:21]))\n",
    "    char_array = np.array(char_array).T\n",
    "    string = \"\"\n",
    "    for row in char_array:\n",
    "        string += \"\".join(row) + \"\\n\"\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 17)\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "NN\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "--\n",
      "-x\n",
      "XX\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed = inputs[0][:3 * 22 - 1].copy()  # 3 cols * 18 tiles per col - newline char (to be generated)\n",
    "seed[22+19] = 0\n",
    "seed[22+19][char_to_ix['x']] = 1\n",
    "seed[22*2+19] = 0\n",
    "seed[22*2+19][char_to_ix['x']] = 1\n",
    "print(seed.shape)\n",
    "print(onehot_to_string(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'single_alternate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 'single':\n",
    "    condition_tapess_dir = \"condition_tapes_single\"\n",
    "elif mode == 'single_alternate':\n",
    "    condition_tapess_dir = \"condition_tapes_single_alternate\"\n",
    "elif mode == 'double_alternate':\n",
    "    condition_tapess_dir = \"condition_tapes_double_alternate\"\n",
    "gen_parent_dir = \"lstm_conditional_generate_levels_txt_by_tape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_levels_to_gen = 1\n",
    "level_height = 16 + 1 + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition_tapes_single_alternate\n"
     ]
    }
   ],
   "source": [
    "print(condition_tapess_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e03d39085446c69cb6ebe71f2827bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee0b0816ca2482bb27c3eea788c517b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c0906958a84984b0693de605e477ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56085420a3ea46f2be03d1a772391e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342c0cd77bf142e2ae1df39474de19e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54182217aa9342819dcbd8cf7de5752c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d930a12caa5849abbfbf03784e2329d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de998b0826464b968a6937f589d205ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52589b2a9a464863909b91326711f501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b39a979fe84bfba57465d7afcd5006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3520.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for tape_fname in os.listdir(condition_tapess_dir):\n",
    "    \n",
    "    condition_tapes_path = f\"{condition_tapess_dir}/{tape_fname}\"\n",
    "    gen_dir = f\"{gen_parent_dir}/{tape_fname.split('.')[0]}\"\n",
    "    os.makedirs(gen_dir, exist_ok=True)\n",
    "    \n",
    "    with open(condition_tapes_path, \"r\") as json_f:\n",
    "        condition_tapes = np.array(json.load(json_f))\n",
    "        \n",
    "    num_tile_to_gen = condition_tapes.shape[1] * level_height\n",
    "    \n",
    "    for j in tqdm(range(1, num_levels_to_gen+1)):\n",
    "\n",
    "        seed = inputs[0][:3 * 22 - 1].copy()  # 3 cols * 18 tiles per col - newline char (to be generated)\n",
    "        seed[22+19] = 0\n",
    "        seed[22+19][char_to_ix['x']] = 1\n",
    "        seed[22*2+19] = 0\n",
    "        seed[22*2+19][char_to_ix['x']] = 1\n",
    "        gen = seed.copy()\n",
    "\n",
    "        # initialize all hidden and cell states to zeros\n",
    "        lstm1_h = np.zeros((1, hidden_size))\n",
    "        lstm1_c = np.zeros((1, hidden_size))\n",
    "        lstm2_h = np.zeros((1, hidden_size))\n",
    "        lstm2_c = np.zeros((1, hidden_size))\n",
    "        lstm3_h = np.zeros((1, hidden_size))\n",
    "        lstm3_c = np.zeros((1, hidden_size))\n",
    "\n",
    "        num_condition_chars_to_add = False\n",
    "        col_ix_generating = -1\n",
    "\n",
    "        for i in tqdm(range(num_tile_to_gen), leave=False):\n",
    "\n",
    "            seed = np.expand_dims(seed, axis=0)\n",
    "\n",
    "            # predict probas and update hidden and cell states\n",
    "            probas, lstm1_h, lstm1_c, lstm2_h, lstm2_c, lstm3_h, lstm3_c = model.predict([\n",
    "                seed, lstm1_h, lstm1_c, lstm2_h, lstm2_c, lstm3_h, lstm3_c\n",
    "            ])\n",
    "\n",
    "            # ========== generic prediction ==========\n",
    "\n",
    "            if num_condition_chars_to_add == 0:\n",
    "\n",
    "                probas = probas[0][-1]  # first batch, last timestep\n",
    "\n",
    "                idx = np.random.choice(np.arange(len(probas)), p=probas)\n",
    "                seed = np.zeros((1, vocab_size))\n",
    "                seed[:, idx] = 1.\n",
    "                gen = np.vstack([gen, seed])\n",
    "\n",
    "                if ix_to_char[idx] == '\\n':\n",
    "                    num_condition_chars_to_add = 5\n",
    "                    col_ix_generating += 1\n",
    "\n",
    "            # ========== condition char are not generated, they are loaded from the condition tape ==========\n",
    "\n",
    "            else:\n",
    "\n",
    "                seed = np.zeros((1, vocab_size))\n",
    "\n",
    "                if num_condition_chars_to_add == 5:\n",
    "                    condition_tape = condition_tapes[0]\n",
    "                elif num_condition_chars_to_add == 4:\n",
    "                    condition_tape = condition_tapes[1]\n",
    "                elif num_condition_chars_to_add == 3:\n",
    "                    condition_tape = condition_tapes[2]\n",
    "                elif num_condition_chars_to_add == 2:\n",
    "                    condition_tape = condition_tapes[3]\n",
    "                elif num_condition_chars_to_add == 1:\n",
    "                    condition_tape = condition_tapes[4]\n",
    "\n",
    "                if condition_tape[col_ix_generating] == 0:\n",
    "                    seed[:, char_to_ix['N']] = 1\n",
    "                elif condition_tape[col_ix_generating] == 1:\n",
    "                    seed[:, char_to_ix['Y']] = 1\n",
    "                gen = np.vstack([gen, seed])\n",
    "\n",
    "                num_condition_chars_to_add -= 1\n",
    "\n",
    "        with open(f'{gen_dir}/{j}.txt', 'w+') as txt_f:\n",
    "            txt_f.write(onehot_to_string(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NNN\\nNNN\\nNNN\\nNNN\\nNNN\\n---\\n---\\n---\\n---\\n---\\n---\\n---\\n---\\n---\\n---\\n---\\n---\\n---\\n---\\n-xx\\nXXX\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_to_string(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
